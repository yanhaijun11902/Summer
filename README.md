### 2. DMLP with Three Hidden Layers

#### (1) Weight Matrix U1, U2, U3, U4
The weight matrices for each layer are as follows according to Eq. (4.1):

- **U1:**
    - \(u_{11} = 0.3\), \(u_{12} = -0.1\)
    - \(u_{21} = 1.0\), \(u_{22} = 0.3\)
    - \(u_{31} = -0.5\), \(u_{32} = 0.8\)

- **U2:**
    - \(u_{11} = 1\), \(u_{12} = 0\)
    - \(u_{21} = 0\), \(u_{22} = 1\)

- **U3:**
    - \(v_{11} = 0.5\), \(v_{12} = 0\)
    - \(v_{21} = -0.5\), \(v_{22} = -2\)

- **U4:**
   The weights are not provided in the image.

#### (2) Output \(o\) with Input \(x = (1,0)^T\) and Logistic Sigmoid Activation Function
I need to calculate the output using the logistic sigmoid activation function and given weights.

#### (3) Output \(o\) with Input \(x = (1,0)^T\) and ReLU Activation Function
I need to calculate the output using ReLU activation function and given weights.

#### (4) Effect of Reducing the Weight from \(u_2\) from \(u_{21}\) from \(u_{22}\) on Error when Expected Output \(o = (1,0)^T\)
Reducing the weight of \(u_2\) from \(u_{21}\) from \(u_{22}\) would affect how strongly this neuron influences the final output of the network during forward propagation.
